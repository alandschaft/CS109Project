{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "## We considered to use clinical trials clustering as the basic algorithm for our search application, so these file documents some experiments. At the end, we decided to use a different approach (based on term frequencies and tf-idf based cosine distance), because it fitted better the requirements of our project. Mainly, the requirement to present frequent terms that also cover large part of the dataset. So, again, this file documents only some experiments. \n",
    "\n",
    "The goal of this step is to present the users with a set of key terms for the data and allow them to select interesting tags interactively to narrow the results.\n",
    "\n",
    "The process can be divided into two stages:\n",
    "\n",
    "1. Data preprocessing\n",
    "2. User interaction\n",
    "\n",
    "Stage (1) comprises two main procedures. First, the terms are transformed into *term vectors*, where each column corresponds to each term in the dataset and each row corresponds to each document. The elements are then assigned weights; these can be either a simple binary measures (1 - the term is present in the given document; 0 - the term does not appear in the document) or statistical ranks of importance of the given term to the given document (such as TF-IDF or G2).\n",
    "\n",
    "    Example: for the documents [\"Mary had\", \"a little lamb\"], term vectors with a binary measure would be (let's assume the terms are sorted in alphabatical order):\n",
    "\n",
    "    [[0, 1, 0, 0, 1], #Document 1\n",
    "    [1, 0, 1, 1, 0]]\n",
    "    \n",
    "The second step of data preprocessing is to calculate, for each document, its K nearest neighbours. These will be used to find the most relevant terms for display after the user selects a tag at the user interaction stage.\n",
    "\n",
    "Stage (2) is user interaction. Initially, a set of highest-ranking terms for the entire dataset (calculated on the basis of the term vectors) is displayed to the user along with an input field. Once the user selects a term from the list, documents containing the term are selected. For each of the matched document, its neighbours are selected from the nearest neighbour list. Finally, the terms of the matched documents and neghbours are used to generate a more focused input list for user selection and the process is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from math import log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: C:\\Study\\CS102\\project\\project2\\repro\\CS109Project\\data\n"
     ]
    }
   ],
   "source": [
    "# Set working directory as the current directory of the ipython notebook\n",
    "working_dir = os.getcwd()\n",
    "data_dir = os.path.join(working_dir, 'data')\n",
    "print(\"Data directory: %s\" % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the serialized results of MetaMap processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>criteria_id</th>\n",
       "      <th>ngram_index</th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "      <th>cui</th>\n",
       "      <th>stype</th>\n",
       "      <th>cid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((time, NN),)</td>\n",
       "      <td>NCT00001149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>Time</td>\n",
       "      <td>C0040223</td>\n",
       "      <td>tmco</td>\n",
       "      <td>[G01.910]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((uncontrolled, VBN), (seizure, NNS), (at, IN))</td>\n",
       "      <td>NCT00001149</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16.21</td>\n",
       "      <td>Seizures</td>\n",
       "      <td>C0036572</td>\n",
       "      <td>sosy</td>\n",
       "      <td>[C10.228.140.490.631, C10.597.742, C23.888.592...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((of, IN), (seizure, NNS), (during, IN))</td>\n",
       "      <td>NCT00001149</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16.21</td>\n",
       "      <td>Seizures</td>\n",
       "      <td>C0036572</td>\n",
       "      <td>sosy</td>\n",
       "      <td>[C10.228.140.490.631, C10.597.742, C23.888.592...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((seizure, NNS), (at, IN), (the, DT))</td>\n",
       "      <td>NCT00001149</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16.21</td>\n",
       "      <td>Seizures</td>\n",
       "      <td>C0036572</td>\n",
       "      <td>sosy</td>\n",
       "      <td>[C10.228.140.490.631, C10.597.742, C23.888.592...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((pattern, NN), (of, IN), (seizure, NNS))</td>\n",
       "      <td>NCT00001149</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16.07</td>\n",
       "      <td>Seizures</td>\n",
       "      <td>C0036572</td>\n",
       "      <td>sosy</td>\n",
       "      <td>[C10.228.140.490.631, C10.597.742, C23.888.592...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ngram       nct_id  criteria_id  \\\n",
       "0                                    ((time, NN),)  NCT00001149            0   \n",
       "1  ((uncontrolled, VBN), (seizure, NNS), (at, IN))  NCT00001149            0   \n",
       "2         ((of, IN), (seizure, NNS), (during, IN))  NCT00001149            0   \n",
       "3            ((seizure, NNS), (at, IN), (the, DT))  NCT00001149            0   \n",
       "4        ((pattern, NN), (of, IN), (seizure, NNS))  NCT00001149            0   \n",
       "\n",
       "   ngram_index  score      term       cui stype  \\\n",
       "0            0   8.34      Time  C0040223  tmco   \n",
       "1            8  16.21  Seizures  C0036572  sosy   \n",
       "2           10  16.21  Seizures  C0036572  sosy   \n",
       "3           11  16.21  Seizures  C0036572  sosy   \n",
       "4           12  16.07  Seizures  C0036572  sosy   \n",
       "\n",
       "                                                 cid  \n",
       "0                                          [G01.910]  \n",
       "1  [C10.228.140.490.631, C10.597.742, C23.888.592...  \n",
       "2  [C10.228.140.490.631, C10.597.742, C23.888.592...  \n",
       "3  [C10.228.140.490.631, C10.597.742, C23.888.592...  \n",
       "4  [C10.228.140.490.631, C10.597.742, C23.888.592...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(os.path.join(data_dir, 'mm.pckl'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate term vectors and document clusters\n",
    "\n",
    "Generating clusters in done in two steps.\n",
    "\n",
    "1. First, for each document, rank the set of terms for the document with G2 scores. \n",
    "2. Then, for each document, generate clusters of K most similar documents.\n",
    "\n",
    "By default the term ranking stage uses MetaMap CUIs for terms; this can be configured as a parameter to the respective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g2(a, b, c, d):\n",
    "    \"\"\" Calculate Dunning's log-likelihood score\n",
    "\n",
    "    :param a: term frequency in corpus 1\n",
    "    :type a: double\n",
    "    :param b: term frequency in corpus 2\n",
    "    :type b: double\n",
    "    :param c: corpus 1 frequency of other terms (size - a)\n",
    "    :type c: double\n",
    "    :param d: corpus 2 frequency of other terms (size - b)\n",
    "    :type d: double\n",
    "    :return: log-likelihood score\n",
    "    :rtype: double\n",
    "    \"\"\"\n",
    "    a = a + 1.0\n",
    "    b = b + 1.0\n",
    "    c = c + 1.0\n",
    "    d = d + 1.0\n",
    "    G2 = 2 * (\n",
    "        a * log(a) + b * log(b) + c * log(c) + d * log(d) - (a + b) * log(a + b) - (a + c) * log(a + c) - (b + d) * log(\n",
    "            b + d) - (c + d) * log(c + d) + (a + b + c + d) * log(a + b + c + d))\n",
    "    return G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def term_frequencies(data, column='cui'):\n",
    "    \"\"\" Returns the frequency map for the given column (defaults to 'cui'). \n",
    "    Used to generate term frequencies for the whole dataset, which are consulted in term score generation.\n",
    "    \n",
    "    :param data: MetaMap-tagged dataframe\n",
    "    :type data: DataFrame\n",
    "    :param column: column containing the terms whose frequencies are to be generated\n",
    "    :type column: str\n",
    "    \"\"\"\n",
    "    return data[column].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_data(data, column='cui', key='nct_id'):\n",
    "    \"\"\" Groups rows sharing the same key (defaults to 'nct_id') \n",
    "    and collapses values of the specified column (defaults to 'cui') into a list.\n",
    "    \n",
    "    Used to transform MetaMap-tagged data (one row per MetaMap term) into a document-term matrix.\n",
    "    \n",
    "    :param data: MetaMap-tagged dataframe\n",
    "    :type data: DataFrame\n",
    "    :param column: the column whose values to collapse into a list\n",
    "    :type column: str\n",
    "    :param key: the column to group the data by\n",
    "    :type key: str\n",
    "    \"\"\"\n",
    "    grouped = data.groupby(data[key])\n",
    "    aggregated = grouped.agg({column: lambda x: x.tolist()})\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_terms(freq_map, aggregated, column='cui'):\n",
    "    \"\"\" Ranks the terms in the given column (defaults to 'cui') with G2 similarity.\n",
    "    \n",
    "    :param freq_map: the dataset frequency map calculated by \"term_frequencies\"\n",
    "    :type freq_map: Series\n",
    "    :param aggregated: the data converted to a document-term matrix, generated by \"aggregate_data\"\n",
    "    :type aggregated: DataFrame\n",
    "    :param columm: the name of the column containing the data\n",
    "    :type column: string\n",
    "    \"\"\"\n",
    "    def calc_freqs(r):\n",
    "        k,v = np.unique(r, return_counts=True)\n",
    "        return dict(zip(k,v))\n",
    "\n",
    "    scores = [] # 2D matrix: 1 document per row, 1 term per column\n",
    "    corpus_size = freq_map.sum()\n",
    "    for row in aggregated[column].get_values():\n",
    "        doc_freqs = calc_freqs(row)\n",
    "        doc_size = sum(doc_freqs.values())\n",
    "        doc_vector = []\n",
    "        for term, freq in freq_map.iteritems():\n",
    "            a = int(doc_freqs[term]) if term in doc_freqs else 0\n",
    "            b = freq\n",
    "            c = doc_size - a\n",
    "            d = corpus_size - b\n",
    "            score = g2(a,b,c,d)\n",
    "            doc_vector.append(score)\n",
    "        scores.append(doc_vector)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_clusters(term_vectors, k=50):\n",
    "    \"\"\" Generates k nearest neighbours for the provided document-term score matrix.\n",
    "    Outputs a matrix of distances and a matrix of indices of the neighbours in the aggregated data set.\n",
    "    Both matrices have one row per document, one column per neighbour.\n",
    "    \n",
    "    :param term_vectors: the term scores per document calculated by \"rank_terms\"\n",
    "    :type term_vectors: ndarray\n",
    "    :param k: the number of nearest neighbours to generate\n",
    "    :type k: int\n",
    "    \"\"\"\n",
    "    real_k = min(k, len(term_vectors))\n",
    "    nn = NearestNeighbors(n_neighbors=real_k, algorithm='ball_tree').fit(term_vectors)\n",
    "    distances, indices = nn.kneighbors(term_vectors)\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*term_frequencies(data_frame)* returns the counts for each term (CUI) across the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C0030705    11009\n",
       "C0036572     9953\n",
       "C0019664     7490\n",
       "C0019665     7490\n",
       "C0012634     6862\n",
       "Name: cui, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_map = term_frequencies(df)\n",
    "freq_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*aggregate_data(data_frame)* groups the MetaMap-tagged data (one row per one MM tag) according to the NCT ID of the original document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cui</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nct_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NCT00001149</th>\n",
       "      <td>[C0040223, C0036572, C0036572, C0036572, C0036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00001192</th>\n",
       "      <td>[C0030705, C3661466, C0042960, C0033927, C0033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00001205</th>\n",
       "      <td>[C0021081, C0039798, C0030705, C0008059, C0001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00001218</th>\n",
       "      <td>[C0031206, C0018684, C0031206, C0018684, C1708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00001262</th>\n",
       "      <td>[C0012634, C0235031, C0012634, C0021270, C0235...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           cui\n",
       "nct_id                                                        \n",
       "NCT00001149  [C0040223, C0036572, C0036572, C0036572, C0036...\n",
       "NCT00001192  [C0030705, C3661466, C0042960, C0033927, C0033...\n",
       "NCT00001205  [C0021081, C0039798, C0030705, C0008059, C0001...\n",
       "NCT00001218  [C0031206, C0018684, C0031206, C0018684, C1708...\n",
       "NCT00001262  [C0012634, C0235031, C0012634, C0021270, C0235..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df = aggregate_data(df)\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rank_terms(frequency_map, aggregated_terms)* calculates the scores for each term per each document. It returns a list where each row corresponds to each document in *aggregated* and each column corresponds to each term in *frequency_map*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.48128593e+01   3.73000780e+01   1.30281259e+01 ...,   1.21529518e+01\n",
      "    1.21529518e+01   1.21529518e+01]\n",
      " [  8.26224573e-02   8.41583529e-01   1.00962763e+01 ...,   1.30425651e+01\n",
      "    1.30425651e+01   1.30425651e+01]\n",
      " [  7.58073218e+00   1.36250735e+01   9.11352458e+00 ...,   1.00081409e+01\n",
      "    1.00081409e+01   1.00081409e+01]\n",
      " ..., \n",
      " [  5.22303822e-01   3.55070137e-01   6.95985006e-02 ...,   1.35502672e+01\n",
      "    1.35502672e+01   1.35502672e+01]\n",
      " [  1.16574127e+00   1.12555932e+01   7.40998322e+00 ...,   1.02879057e+01\n",
      "    1.02879057e+01   1.02879057e+01]\n",
      " [  1.09748542e-03   3.07013192e+00   1.15059729e-01 ...,   1.47742748e+01\n",
      "    1.47742748e+01   1.47742748e+01]]\n"
     ]
    }
   ],
   "source": [
    "term_vectors = rank_terms(freq_map, agg_df)\n",
    "print term_vectors[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*generate_clusters(term_vectors, k_neighbours)* calculates *k* nearest neighbours for each document. It returns (1) a list of distances between each document and its neighbours (the smaller the better) and (2) a list of indices of documents in the original data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.           93.31178852   93.66380314 ...,  100.75898977  101.4364923\n",
      "   103.48011933]\n",
      " [   0.          145.83035197  153.42381646 ...,  156.69696465  157.7790185\n",
      "   157.85909544]\n",
      " [   0.          319.26218212  328.75135917 ...,  359.57536786\n",
      "   360.15883844  360.17595347]\n",
      " ..., \n",
      " [   0.          244.77781111  246.4852524  ...,  252.02956025\n",
      "   252.70038576  252.9716634 ]\n",
      " [   0.          172.9420408   182.72826205 ...,  187.12053273\n",
      "   187.73843008  187.81298789]\n",
      " [   0.          259.93173628  260.66232062 ...,  263.53621165  263.9977189\n",
      "   264.03799299]] [[   0  126  179 ...,  141  295  444]\n",
      " [   1  568  295 ..., 1153 1200  289]\n",
      " [   2  227  311 ...,  197  194  152]\n",
      " ..., \n",
      " [1333  685  192 ...,  194  152  196]\n",
      " [1334  192  441 ...,  196 1069 1281]\n",
      " [1335  194  390 ...,  246  171  219]]\n",
      "169.923166059 107.409757613\n"
     ]
    }
   ],
   "source": [
    "cluster_distances, cluster_indices = generate_clusters(term_vectors, k=10)\n",
    "print cluster_distances, cluster_indices\n",
    "print np.mean(cluster_distances), np.std(cluster_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to run the full clustering pipeline and serialize the intermediate and final results so they can be used later by other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clustering_pipeline(data, data_column='cui', aggregate_key='nct_id', k=10):\n",
    "    \"\"\" Wraps up the individual clustering steps (frequency calculation, term ranking, etc.) in a processing pipeline.\n",
    "    Returns the frequency map, aggregated data, term scores, neighbour distances and neighbour indices.\n",
    "    \n",
    "    :param data: the original MetaMap-tagged data to score and cluster\n",
    "    :type data: DataFrame\n",
    "    :param data_column: the column in the original dataframe containing the terms to score\n",
    "    :type data_column: str\n",
    "    :param aggregate_key: the column in the original dataframe to aggregate the data by\n",
    "    :type aggregate_key: str\n",
    "    :param k: the number of neighbours to find for each document\n",
    "    :type k: int\n",
    "    \"\"\"\n",
    "    freq_map = term_frequencies(data)\n",
    "    agg_df = aggregate_data(data)\n",
    "    term_vectors = rank_terms(freq_map, agg_df)\n",
    "    cluster_distances, cluster_indices = generate_clusters(term_vectors)\n",
    "    return freq_map, agg_df, term_vectors, cluster_distances, cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_map, agg_df, term_vectors, cluster_distances, cluster_indices = clustering_pipeline(df, 'cui', 'nct_id', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_data(data_dir, freq_map, agg_df, term_vectors, cluster_distances, cluster_indices):\n",
    "    print \"Serializing freq_map to %s\" % os.path.join(data_dir, 'clust_fm.pckl')\n",
    "    freq_map.to_pickle(os.path.join(data_dir, 'clust_fm.pckl'))\n",
    "    print \"Serializing agg_df to %s\" % os.path.join(data_dir, 'clust_agg.pckl')\n",
    "    agg_df.to_pickle(os.path.join(data_dir, 'clust_agg.pckl'))\n",
    "    print \"Serializing term_vectors to %s\" % os.path.join(data_dir, 'clust_tv.pckl')\n",
    "    with open(os.path.join(data_dir, 'clust_tv.pckl'), 'wb') as fh:\n",
    "        pickle.dump(term_vectors, fh)\n",
    "    print \"Serializing cluster_distances to %s\" % os.path.join(data_dir, 'clust_cd.pckl')\n",
    "    with open(os.path.join(data_dir, 'clust_cd.pckl'), 'wb') as fh:    \n",
    "        pickle.dump(cluster_distances, fh)\n",
    "    print \"Serializing cluster_indices to %s\" % os.path.join(data_dir, 'clust_ci.pckl')\n",
    "    with open(os.path.join(data_dir, 'clust_ci.pckl'), 'wb') as fh:    \n",
    "        pickle.dump(cluster_indices, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing freq_map to C:\\Study\\CS102\\project\\project2\\repro\\CS109Project\\data\\clust_fm.pckl\n",
      "Serializing agg_df to C:\\Study\\CS102\\project\\project2\\repro\\CS109Project\\data\\clust_agg.pckl\n",
      "Serializing term_vectors to C:\\Study\\CS102\\project\\project2\\repro\\CS109Project\\data\\clust_tv.pckl\n",
      "Serializing cluster_distances to C:\\Study\\CS102\\project\\project2\\repro\\CS109Project\\data\\clust_cd.pckl\n",
      "Serializing cluster_indices to C:\\Study\\CS102\\project\\project2\\repro\\CS109Project\\data\\clust_ci.pckl\n"
     ]
    }
   ],
   "source": [
    "write_data(data_dir, freq_map, agg_df, term_vectors, cluster_distances, cluster_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
